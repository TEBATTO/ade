import joblib
import streamlit as st
import numpy as np
import pandas as pd
import seaborn as sns
import plotly.express as px
import matplotlib.pyplot as plt
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    roc_auc_score,
    roc_curve,
    auc
)

# === Configuration de la page ===
st.set_page_config(page_title="D√©tection de Fraude Bancaire", layout="wide", page_icon="üí≥")

# === Chargement des donn√©es ===
@st.cache_data
def load_data():
    return pd.read_csv("creditcard.csv")

df_creditcard = load_data()

# === Th√®me de l'application ===
def custom_css():
    st.markdown(
        """
        <style>
        .main {
            background-color: #f5f5f5;
        }
        .stButton button {
            background-color: #4CAF50;
            color: white;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

custom_css()

# === Titre de l'application ===
st.markdown("<h1 style='text-align: center; color: #4CAF50;'>D√©tection de Fraude Bancaire</h1>", unsafe_allow_html=True)

# === Barre lat√©rale ===
st.sidebar.title("Sommaire")
pages = ["Contexte du projet", "Exploration des donn√©es", "Analyse de donn√©es", "Mod√©lisation"]
page = st.sidebar.radio("Aller vers la page :", pages)

# === Contexte du projet ===
if page == pages[0]: 
    # Contexte du projet
    st.write("### Contexte du projet")
    st.write("""
    Ce projet s'inscrit dans un contexte bancaire. L'objectif est de d√©velopper une solution 
    de d√©tection de fraude bancaire en utilisant l'analyse de donn√©es et le machine learning avec Python.
    """)
    st.write("""
    Nous avons √† notre disposition le fichier `creditcard.csv` contenant des donn√©es de transactions bancaires. 
    Chaque observation en ligne correspond √† une transaction, et chaque variable en colonne est une caract√©ristique de la transaction.
    """)
    st.write("""
    Dans un premier temps, nous explorerons ce dataset. Ensuite, nous analyserons visuellement les donn√©es, 
    avant d'impl√©menter des mod√®les de Machine Learning pour pr√©dire la classe de la transaction.
    """)
    st.image("detection_fraude.jpeg")

# === Exploration des donn√©es ===
elif page == pages[1]:
    st.write("### Exploration des donn√©es")
    st.write("Voici un aper√ßu des donn√©es utilis√©es dans ce projet :")
    st.dataframe(df_creditcard.head())
    st.write(f"Dimensions du dataset : {df_creditcard.shape}")

    if st.checkbox("Afficher les valeurs manquantes"): 
        st.write(df_creditcard.isna().sum())
        
    if st.checkbox("Afficher les doublons"): 
        st.write("Nombre de doublons :", df_creditcard.duplicated().sum())

# === Analyse de donn√©es ===
elif page == pages[2]:
    st.write("### Analyse de donn√©es")
    
    # Distribution de la variable cible
    st.write("#### Distribution de la variable cible (Class)")
    fig1, ax1 = plt.subplots()
    sns.countplot(x='Class', data=df_creditcard, ax=ax1, palette="coolwarm")
    ax1.set_title("Distribution des classes")
    st.pyplot(fig1)

    # Matrice de corr√©lation
    st.write("#### Matrice de corr√©lation")
    fig2, ax2 = plt.subplots(figsize=(10, 8))
    sns.heatmap(df_creditcard.corr(), annot=False, cmap='coolwarm', ax=ax2)
    st.pyplot(fig2)

    # Visualisation interactive avec Plotly
    st.write("#### Visualisation interactive")
    fig3 = px.scatter(
        df_creditcard, x="Time", y="Amount", color="Class", 
        title="Montant des transactions dans le temps",
        labels={"Amount": "Montant", "Time": "Temps"}
    )
    st.plotly_chart(fig3)

# === Mod√©lisation ===
elif page == pages[3]:
    st.write("### Mod√©lisation")
    
    # S√©paration des donn√©es
    X = df_creditcard.drop(columns=['Class'], axis=1)
    y = df_creditcard['Class']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # Normalisation
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    
    # Chargement des mod√®les sauvegard√©s
    reg_log = joblib.load("modele_regression_logistique.pkl")
    rf = joblib.load("optimized_random_forest.pkl")
    xgb = joblib.load("xgboost_optimise.pkl")
    
    # Pr√©dictions
    model_choisi = st.selectbox(label="Choisissez un mod√®le :", options=["R√©gression Logistique", "Random Forest", "XGBoost"])
    
    if model_choisi == "R√©gression Logistique":
        y_pred = reg_log.predict(X_test)
        proba = reg_log.predict_proba(X_test)[:, 1]
    elif model_choisi == "Random Forest":
        y_pred = rf.predict(X_test)
        proba = rf.predict_proba(X_test)[:, 1]
    elif model_choisi == "XGBoost":
        y_pred = xgb.predict(X_test)
        proba = xgb.predict_proba(X_test)[:, 1]

    # Matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    st.write("#### Matrice de Confusion :")
    st.write(cm)

    # Rapport de classification
    st.write("#### Rapport de Classification :")
    st.text(classification_report(y_test, y_pred, target_names=["Non-Fraude", "Fraude"]))

    # Courbe ROC
    st.write("#### Courbe ROC")
    fpr, tpr, _ = roc_curve(y_test, proba)
    auc_score = auc(fpr, tpr)
    fig4, ax4 = plt.subplots()
    ax4.plot(fpr, tpr, label=f"AUC = {auc_score:.2f}")
    ax4.set_title("Courbe ROC")
    ax4.set_xlabel("Taux de Faux Positifs")
    ax4.set_ylabel("Taux de Vrais Positifs")
    ax4.legend(loc="best")
    st.pyplot(fig4)

# === Pied de page ===
st.markdown("<p style='text-align: center;'>D√©velopp√© avec ‚ù§Ô∏è en Streamlit par Tebatto</p>", unsafe_allow_html=True)
